{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM for sentiment analysis on 1.6 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/imacair/Desktop/Products3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Final_Manual_0805.csv', encoding='latin1',delimiter=',')\n",
    "data.message = data.message.str.encode('ascii','replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data= data.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['message','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data2 = pd.read_csv('Final_Manual_0805.csv', encoding='latin1',delimiter=',')\n",
    "#data2 = data2[['message','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250\n",
      "9750\n"
     ]
    }
   ],
   "source": [
    "print(data[ data['sentiment'] == 0].size)\n",
    "print(data[ data['sentiment'] == 4].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'#llbite ankyl', u'#as 3 things ', u'watch physici',\n",
       "       u'i dont know i', u'#imaginedrago', u'chinese medic',\n",
       "       u'pain relief f', u'suffering fro', u'herself goodw',\n",
       "       u'how they did ', u'imagine drago', u'the progressi', u'rt ',\n",
       "       u'imagine drago', u'imagine drago', u'chinese tradi',\n",
       "       u'imagine drago', u'imagine drago', u'imagine drago',\n",
       "       u'imagine drago', u'great to be b', u'ankylosing sp',\n",
       "       u'@doctorcaldwe', u'.@imaginedrag', u'what is #anky',\n",
       "       u'how they did ', u'252.?????????', u'via @medcityn',\n",
       "       u'ankylosing sp', u'my boyfriend ', u'osteoporosis ',\n",
       "       u'gut microbiot', u'decreased hea', u'new2trip: tof',\n",
       "       u'#plantarfasci', u'i knew there ', u'thank you @pe',\n",
       "       u'the ever grow', u'exclusive: im', u'ankylosing sp',\n",
       "       u'#3 mental hea', u'learn more ab', u'ankylosing sp',\n",
       "       u'i need two hi', u'upper cervica', u'new ankylosin',\n",
       "       u'@adamrickitt ', u'too fucking t', u'crank up the ',\n",
       "       u'#nationalanky', u'happiest comp', u'ctla-4 bound ',\n",
       "       u'a small drug ', u'#icymi biomar', u'#bristolmyers',\n",
       "       u'bristol-myers', u'bristol-myers', u'bristol-myers',\n",
       "       u'$pfe, $bmy, $', u'senior patien', u'associate dir',\n",
       "       u'intact invest', u'stock-researc', u'amf pensionsf',\n",
       "       u'bristol-myers', u'scotia capita', u'associate dir',\n",
       "       u'associate dir', u'biomarker lea', u'director corp',\n",
       "       u'associate dir', u'stocks on tra', u'regional logi',\n",
       "       u'buy your spir', u'analysts near', u'bristol-myers',\n",
       "       u'NAa good stor', u'bms opdivo re', u'#biopharm #bi',\n",
       "       u'new #job: cou', u'bristol-myers', u'bristol-myers',\n",
       "       u'#bristolmyers', u'#bristolmyers', u'bristol-myers',\n",
       "       u'$bmy: #opdivo', u'#bristolmyers', u'bristol-myers',\n",
       "       u'#bristolmyers', u'#bristolmyers', u'#bristolmyers',\n",
       "       u'#bristolmyers', u'started the d', u'bristol-myers',\n",
       "       u'#bristolmyers', u'$bmy: bristol', u'bristolmyers ',\n",
       "       u'brief bristol', u'#clinicalappr', u'bristol-myers',\n",
       "       u'biologic-naiv', u'@denisenolson', u'@kimlovestree',\n",
       "       u'@elisesrn1 @k', u'i have been o', u'@drwadeg @sen',\n",
       "       u'stay uptodate', u'same with enb', u'@papa6611 @be',\n",
       "       u'@berniesander', u'when you wear', u'@mariatcardon',\n",
       "       u'@thedemocrats', u'@crampell @ma', u'@jmscubfan @m',\n",
       "       u'@theplumlineg', u'@mariatcardon', u'@tiffanykhou ',\n",
       "       u'@mariatcardon', u'@2014 @amgen ', u'#trumpbudget ',\n",
       "       u'so #enbrel ga', u'data presente', u'we are lookin',\n",
       "       u'@spondylitis ', u'*every time a', u'@dogloverrn8 ',\n",
       "       u'@lov3jonez no', u'@lov3jonez yo', u'this is the 1',\n",
       "       u'looks like #e', u'the latest my', u'@exhaustipate',\n",
       "       u'#samsungbioep', u'novartis says', u'new to this p',\n",
       "       u'i made it thr', u'regram of our', u'any #rheum fo',\n",
       "       u'@elainak84 @j', u'auto-injector', u'i have four u',\n",
       "       u'drug company ', u'enbrel prescr', u\"alright y'all\",\n",
       "       u'has anyone ev', u'after two yea', u'@sensanders i',\n",
       "       u'this is me ev', u'so yeah, if y', u'life saving i',\n",
       "       u'#abbvie: stan', u'abbvie: stand', u'abbvie: stand',\n",
       "       u'@odibro lol. ', u'a serious thr', u'$halo pegph20',\n",
       "       u'$tgtx imbruvi', u'for those w/ ', u'#golf #golfne',\n",
       "       u'climate chang', u'the most frus', u'augusta stunn',\n",
       "       u'having psoria', u'psoriasis on ', u'its bullshit ',\n",
       "       u'my psoriasis ', u'@taichoumars ', u'@carlahatley ',\n",
       "       u'consolidating', u'bottom line, ', u'#fda pulls ap',\n",
       "       u'trilipix has ', u'in france.re ', u'...rash, or d',\n",
       "       u'$abbv & $jnj ', u'regulatory de', u'franklin grah',\n",
       "       u'$tgtx did i m', u'$tgtx got 2 a', u'@irwintap @an',\n",
       "       u'find the alte', u'a lack of cle', u'us masters: d',\n",
       "       u'ah, the good ', u'boris johnson', u'pga champions',\n",
       "       u'several condi', u'@flakyfred as', u'management of',\n",
       "       u'investigation', u'#psoriasis is', u'no pain meds,',\n",
       "       u'smoking is th', u'lady gaga suf', u'low cost acto',\n",
       "       u'this goat nee', u'if you cannot', u'it pays to sw',\n",
       "       u'this panther ', u'this shrew ne', u'this porcupin',\n",
       "       u'where did it ', u'this ram need', u'this wolverin',\n",
       "       u'this monkey n', u'this raccoon ', u'this crow nee',\n",
       "       u'this sloth ne', u'this chipmunk', u'@billmiller32',\n",
       "       u'astrazeneca, ', u'interesting t', u'@jacobplieth ',\n",
       "       u'$tgtx imbruvi', u'@lin_ling_88 ', u'$tgtx tg-1101',\n",
       "       u\"$tgtx i've tr\", u'$tgtx imbruvi', u'garden bridge',\n",
       "       u'i think the n', u'i liked a @yo', u'amazon replac',\n",
       "       u'spacex has a ', u'robotics, sma', u'the rock<u+20',\n",
       "       u\"don't let pso\", u'psoriasis? wh', u'active pharma',\n",
       "       u'natural cure ', u'diets & weigh', u\"don't let joi\",\n",
       "       u'research show', u'do you suffer', u'x-ray remains',\n",
       "       u'olives: can p', u'#arthritis ne', u'.. one pan...',\n",
       "       u'start your di', u'the \"help me\"', u'pharmacyclics',\n",
       "       u'imbruvica (ib', u'@shrinkthinks', u'imbruvica con',\n",
       "       u'#bioplus imbr', u'imbruvica con', u\"$tgtx u can't\",\n",
       "       u'@orbvase it m', u'$tgtx i luv w', u'$tgtx follow ',\n",
       "       u'$tgtx does ev', u'@orbvase look', u'$tgtx forget ',\n",
       "       u'$tgtx imbruvi', u'$tgtx imbruvi', u'$tgtx combo t',\n",
       "       u'$tgtx imbruvi', u'$tgtx tg-1101', u'$tgtx follow ',\n",
       "       u'$tgtx focus!!', u'$tgtx imbruvi', u\"nfa's jawaun \",\n",
       "       u\"#np: le'andri\", u'metriopharm a', u'metriopharm a',\n",
       "       u'metriopharm a', u'pharmamktnet:', u'metriopharm a',\n",
       "       u'gastroenterro', u'abbvie receiv', u'i honestly co',\n",
       "       u'if you have r', u'@cannabstore ', u'this lion nee',\n",
       "       u'the biggest t', u\"pharma's most\", u'after a coupl',\n",
       "       u'my eyelids we', u'@austindobby ', u\"i'm ericka i \",\n",
       "       u'#onewordoffbo', u'pictures of p', u'with rheumato',\n",
       "       u'trilipix.... ', u'promised choi', u'affordable he',\n",
       "       u'@realdonaldtr', u'thanks to med', u'wow, #imbruvi',\n",
       "       u'$tgtx imbruvi', u'hours before ', u'flipping hous',\n",
       "       u'dwayne johnso', u'in a confusio', u'feb 2017.mitc',\n",
       "       u'chad johnson ', u'love your sis', u'trump invited',\n",
       "       u'#weneedmore: ', u'no bones abou', u'navy league 2',\n",
       "       u'now playing j', u'@public_cultu', u'my easter wre',\n",
       "       u'having a coff', u'\"do not accus', u'@mrjamesob de',\n",
       "       u'so hot outsid', u'@inabbedurtwe', u'ufc 210 previ',\n",
       "       u'call us for y', u'3-d-printed s', u\"le'andria joh\",\n",
       "       u'dwayne johnso', u'nixon prolong', u'two years int',\n",
       "       u'here is my in', u'#bluejays win', u'host #jimmyfa',\n",
       "       u'global automo', u'#nascar #auto', u'butch harmon ',\n",
       "       u'gold bond?pso', u'psoriasis - c', u'what are pust',\n",
       "       u'can your diet', u'berber coffee', u'ginger, citru',\n",
       "       u'research repo', u'abbvie inc. (', u'visit booths ',\n",
       "       u'ginger, citru', u'anyone with #', u'berber coffee',\n",
       "       u'could this pa', u'thunder swamp', u'311nm uvb nar',\n",
       "       u'hemp crete so', u'rosemary tea ', u'bc ppl always',\n",
       "       u'sage, orange,', u'ginger, oatme', u'epigenetic as',\n",
       "       u'7th f-up: mya', u'periodontal b', u'icer releases',\n",
       "       u'inflammation ', u\"when you're a\", u'great review ',\n",
       "       u'rheumatoid ar', u'rheumatoid ar', u'juvenile rheu',\n",
       "       u'rheumatoid ar', u'retweeted a h', u'vitamin d def',\n",
       "       u'kayaker traci', u'chiropractic ', u'what is arthr',\n",
       "       u'rheumatoid ar', u'#orthopedics ', u'epicast repor',\n",
       "       u'how to treat ', u'rheumatoid ar', u'rheumatoid ar',\n",
       "       u\"[editors' cho\", u'malyk walker!', u'treatments in',\n",
       "       u'lupufree now ', u'rheumatoid ar', u'rheumatoid ar',\n",
       "       u'@skeskali i h', u'me: my finger', u'if molecular ',\n",
       "       u'new by @mediv', u'#rheumatic ne', u'as a side not',\n",
       "       u'disease-modif', u'_ ', u'trilipix (fen', u'#hepatitis ne',\n",
       "       u'hepatitis c v', u'globally, 57%', u'hepatitis c s',\n",
       "       u'#diagnostics ', u'the effect of', u'#hepatitis c ',\n",
       "       u'baby boomers ', u'preclinical c', u'randomized, p',\n",
       "       u'mrc technolog', u\"#ehr 'an elec\", u\"i'm at @ensp_\",\n",
       "       u'millie mackin', u'hepatitis c a', u'think you can',\n",
       "       u\"we've license\", u'liver metasta', u'over 1 millio',\n",
       "       u'hepcured prom', u'hepatitis (a,', u'for $6,000, m',\n",
       "       u'just 4 countr', u'what can #por', u'@dutchreniten',\n",
       "       u'more info on ', u'daa treatment', u'afraid @fores',\n",
       "       u'@carson_watch', u'#epigenetics ', u'hiv positive ',\n",
       "       u'#hcv new drug', u'when someone ', u'poster review',\n",
       "       u'@expressscrip', u'patients with', u'can we elimi0',\n",
       "       u'the ways the ', u'[corrigendum]', u\"what's new in\",\n",
       "       u'hcv advocates', u'more monday r', u'read our late',\n",
       "       u'data a0lyses ', u'more baby boo', u'@aarushisahni',\n",
       "       u'our restricti', u\"i'm at hcv ma\", u'@afarray @fed',\n",
       "       u'newer medicat', u'hcv new drugs', u'#sync2017, th',\n",
       "       u'stop pharma p', u'#georgia is t', u'higher rates ',\n",
       "       u'nyu research:', u\"abbvie's pan-\", u'humira: we do',\n",
       "       u'wht an amazin', u'paying full p', u'humana is a d',\n",
       "       u'gotta let it ', u'@drdavidhealy', u'investigation',\n",
       "       u'@grrlmd @kitt', u'@doctorwes @b', u'the joys of g',\n",
       "       u'on set today ', u'that moment w', u'humira is one',\n",
       "       u'@fbz i wonder', u'clumsy finger', u'it would take',\n",
       "       u'humira vs. en', u'oh, boy! a ne', u'@franpatterso',\n",
       "       u'humira is the', u'im posting th', u'i forgot to g',\n",
       "       u'@thebloggess ', u'except for br', u'happy #humira',\n",
       "       u'fucking hate ', u'@thebarbarien', u'the humira in',\n",
       "       u'i have a comp', u'besides your ', u'@chuchukelsey',\n",
       "       u'@colitisninja', u\"@mooreak i'm \", u'@decmannix @d',\n",
       "       u\"it's #humira \", u'patents court', u'@doobarz was ',\n",
       "       u'urge brusied ', u'@lpeckerman i', u'have to see a',\n",
       "       u'is it just me', u'also this...a', u'how much more',\n",
       "       u'my eye is kil', u'i hate humira', u'i start my fi',\n",
       "       u'@msbeeton nic', u\"i've been in \", u\"i don't remem\",\n",
       "       u\"i'm amazed at\", u'prescription:', u'@not_friends ',\n",
       "       u'nhs will use ', u'i survived my', u\"i'm noticing \",\n",
       "       u'@ihaveuc been', u'side effects ', u'@cogita_ante_',\n",
       "       u'get rid of co', u'sweatpants to', u'worst humira ',\n",
       "       u'@ginasabres @', u'uk health ser', u'@mhsindiana i',\n",
       "       u'@sensanders a', u'#e4pbarca #un', u'targeted ther',\n",
       "       u'@dewdiligence', u'would #ibruti', u'ibrutinib-res',\n",
       "       u'inside blood ', u'intriguing mo', u'targeted ther',\n",
       "       u'current resea', u'au oncology r', u'wang reviews ',\n",
       "       u'lw ibrutinib ', u'wang: ibrutin', u'next at fusio',\n",
       "       u'lynn wang fro', u'now lynn wang', u'venetoclax an',\n",
       "       u'abstract: ibr', u'@bloodjournal', u'deciphering #',\n",
       "       u'$tgtx ublitux', u'eha 2016: eva', u'william. sorr',\n",
       "       u'how new ibrut', u'mantle cell l', u'big news at a',\n",
       "       u'understanding', u'reducing ibru', u'@clawbongo wa',\n",
       "       u'comparisons o', u'video: @drrau', u'ibrutinib-res',\n",
       "       u'what are the ', u'@dhovekamp42 ', u'should we che',\n",
       "       u'progression d', u'#myeloma #cli', u'selinexor for',\n",
       "       u'new2trip: ibr', u'what are the ', u'ventricular a',\n",
       "       u'ibrutinib com', u'video: jennif', u'#myeloma #cli',\n",
       "       u'new2trip: ibr', u'dr andrew zel', u'real-world ex',\n",
       "       u'seasonal infl', u'ibrutinib for', u'mutations tie',\n",
       "       u'chemotherapy ', u'venetoclax ma', u'quest diagnos',\n",
       "       u'debate: optim', u'the success o', u'#ibrutinib ma',\n",
       "       u'targeting btk', u'#emjvideo hel', u'ibrutinib for',\n",
       "       u'$tgtx#ublitux', u'im so excited', u'@mustlovemovi',\n",
       "       u'learn about w', u'i seriously j', u'japan grants ',\n",
       "       u\"don't forget \", u'surprise!!!! ', u'so proud to b',\n",
       "       u'abbvie to hig', u'in what city ', u'this award-wi',\n",
       "       u'abbvie: good ', u'rt: to advanc', u'innovation is',\n",
       "       u'meet & networ', u'best pharmace', u'@exciterudy @',\n",
       "       u'@exciterudy @', u'@shortofspoon', u'@shortofspoon',\n",
       "       u'maybe apoe-4 ', u'see how our p', u'12 powerful p',\n",
       "       u'are you a wee', u'most of these', u'this #reading',\n",
       "       u'hey @abbvie -', u'looking for t', u'could the luc',\n",
       "       u'abbvie : japa', u'i had no idea', u'the aana is p',\n",
       "       u'were proud to', u'why she keep ', u'literacy stat',\n",
       "       u\"we're pleased\", u'listen in liv', u'looking to ex',\n",
       "       u'congratulatio', u'abbvie inc. (', u'#abbvie abbvi',\n",
       "       u'abbvie inc. (', u\"we're excited\", u'for these stu',\n",
       "       u'why r doctors', u'what it reall', u'longer surviv',\n",
       "       u'longer surviv', u'#amgen: phase', u'amgen, inc. $',\n",
       "       u'amgen, inc. (', u'amgen, inc. $', u'adalimumab is',\n",
       "       u'our draft gui', u'intravenous o', u'adalimumab, e',\n",
       "       u'guselkumab sh', u'ask your doct', u'drug-induced ',\n",
       "       u'long awaited ', u'my second att', u'growth improv',\n",
       "       u'sandoz biosim', u'aaos study of', u'.@sandoz_glob',\n",
       "       u'efficacy and ', u'why do jia pa', u'.@us_fda appr',\n",
       "       u'do you know h', u'heres to all ', u'work, when an',\n",
       "       u'fingernail ps', u'partnerships ', u'we support ro',\n",
       "       u'@getgutsycana', u'looking forwa', u'first she ben',\n",
       "       u'@liberalblkgi', u'eu approves #', u'patient relat',\n",
       "       u'please join u', u'could you be ', u'thanks! were ',\n",
       "       u'these two dru', u'see all the d', u'japan grants ',\n",
       "       u'amgen to high', u'many thanks t', u'hcr wealth ad',\n",
       "       u'congrats to @', u'adalimumab in', u'fda approves ',\n",
       "       u'the cost for ', u'u.s. fda appr', u'seen earlier ',\n",
       "       u'european comm', u'rct, single-d', u'not making fu',\n",
       "       u'eu approves a', u'he predicted ', u'european comm',\n",
       "       u'it would take', u'european comm', u'european comm',\n",
       "       u'$amgn europea', u'clinical impa', u'effects of pr',\n",
       "       u\"y'all set and\", u'abbvie is und', u'in a blow to ',\n",
       "       u'fujifilm kyow', u'samsung bioep', u'@laurenxexcar',\n",
       "       u'@abbvie i fee', u'abbvie: #humi', u\"yooooo it's @\",\n",
       "       u'abbvie: humir', u'we thank you ', u'@abbvie why i',\n",
       "       u'@thedrisin201', u'i truly belie', u'ties to gilea',\n",
       "       u\"fujifilm's #b\", u'#abbvie abbvi', u\"abbvie's hcv \",\n",
       "       u'abbvie receiv', u'abbvie inc. (', u'@abbvie they ',\n",
       "       u'abbvie : to p', u'drug price re', u'and thank you',\n",
       "       u'want to learn', u'marketing sr ', u'corporate dev',\n",
       "       u'adalimumab am', u'@final100days', u'interesting t',\n",
       "       u'research show', u'(1/2) editori', u'it would take',\n",
       "       u'#healtheconja', u'90 day supply', u'dose #de-esca',\n",
       "       u'new data demo', u'@pharris830 w', u'new data demo',\n",
       "       u'novartis: new', u'new data demo', u'new data demo',\n",
       "       u'novartis inte', u'new data demo', u'baricitinib i',\n",
       "       u'the uk high c', u'the uk high c', u'adalimumab ef',\n",
       "       u'@stevejudgeaz', u'@therealritwi', u'today, young ',\n",
       "       u'we<u+2019>re ', u'we understand', u'janssen and a',\n",
       "       u'thestreet: wh', u'have you appl', u'congratulatio',\n",
       "       u'congratulatio', u'congratulatio', u'congratulatio',\n",
       "       u'i am presenti', u'so proud to c', u'thanks @uabme',\n",
       "       u'we support ro', u'@directrelief', u\"if it weren't\",\n",
       "       u'do you know h', u'here<u+2019>s', u'first she ben',\n",
       "       u\".@abbvie's mo\", u'@liberalblkgi', u'@abbvie  @bio',\n",
       "       u'please join u', u'could you be ', u'thank you amg',\n",
       "       u'ampogen by am', u'.@megtirrell ', u'many thanks @',\n",
       "       u'a huge thank ', u'@craigco62 ju', u'thank you @na',\n",
       "       u'@merceryou co', u'basically amg', u'thank you to ',\n",
       "       u'thanks @nicva', u'the #amgensch', u'so long orlan',\n",
       "       u'amgen will mo', u'thanks to pat', u'amgen files m',\n",
       "       u\"amgen's repat\", u'we had a grea', u\"we'd like to \",\n",
       "       u'thanks to amg', u'thank you to ', u'@live_coverag',\n",
       "       u'as i recall s', u'thanks to @am', u'thanks to @am',\n",
       "       u'the fight aga', u'amgen donates', u'german guy su',\n",
       "       u'biotechnology', u'@amgen thank ', u'so so so happ',\n",
       "       u'#amgen releas', u'fda grants pr', u'thanks to @ge',\n",
       "       u'fda grants pr', u'amgen plans t', u'amgen inc in ',\n",
       "       u'amgen enters ', u\"this didn't t\", u'i feel bad fo',\n",
       "       u'#tech #news a', u'congratulatio', u'congratulatio',\n",
       "       u'if i made a m', u'#leanfit whey', u'joe been told',\n",
       "       u'etanercept, a', u'impact of par', u'#adalimumab &',\n",
       "       u'#biosimilar i', u'@brianintucso', u'waking up at ',\n",
       "       u\"@shams_z won'\", u'adalimumab in', u'the cost for ',\n",
       "       u'rct, single-d', u'#chagas infec', u'the burden of',\n",
       "       u'#job abbvie i', u'#vyopta case ', u'in the advanc',\n",
       "       u'#chagas disea', u'a giant thank', u'#cfroundtable',\n",
       "       u'@abbvie if th', u'#uniteforpark', u'loved working',\n",
       "       u'#abbvie #scho', u'abbvie collea', u'@hillviewprep',\n",
       "       u\"$abbvabbvie's\", u'congratulatio', u'@biosimilarz ',\n",
       "       u'amgen files #', u'we are a team', u'i am so lucky',\n",
       "       u'thanks @vcsta', u'#absoluteshop', u'@jbkinney the',\n",
       "       u'exciting stat', u'#jobs #adjobs', u'#jobs #adjobs',\n",
       "       u'#jobs #adjobs', u'#jobs #adjobs', u'#jobs #adjobs',\n",
       "       u'#jobs #adjobs', u'#jobs #adjobs', u'amgen submits',\n",
       "       u'@stefansieber', u'@abbvie curio', u'congrats to w',\n",
       "       u'worked with h', u'#ilc2017 indu', u'@abbvie @nyti',\n",
       "       u'@abbvie @nyti', u'@abbvie @nyti', u'parp inhibito',\n",
       "       u'#ilc2017 indu', u'in support of', u\"$abbvabbvie's\",\n",
       "       u'#ilc2017 indu', u'two phase 3 s', u'failure of ab',\n",
       "       u'#ilc2017 indu', u\"abbvie's parp\", u\"abbvie's #hum\",\n",
       "       u'abbvie cancer', u'abbvie cancer', u\"it's true. an\",\n",
       "       u'but hats off ', u'@abbvie becau', u'@abbvie  so t',\n",
       "       u'a cool and fu', u'keep on swimm', u'@abbvie i mea',\n",
       "       u'@abbvie that ', u'who<u+2019>s ', u'omg.. this is',\n",
       "       u'speakers from', u'if you were b', u'want to thank',\n",
       "       u'thank you to ', u'we are so pro', u'really @amgen',\n",
       "       u'thanks for th', u'zero motorcyc', u'@dizzydee2000',\n",
       "       u'#boycott big ', u\"hey, don't te\", u'how do your m',\n",
       "       u'we are thrill', u'waiiiting 1h ', u'@metapredict ',\n",
       "       u'this is why y', u\"it's not time\", u'amgen laying ',\n",
       "       u'.@amgendo you', u'every time i ', u'amgen 2017 wo',\n",
       "       u'@amgen #embre', u'#hallmarkies ', u'#bioscience p',\n",
       "       u'patients repo', u'research and ', u'ready to read',\n",
       "       u'this is a med', u'we would like', u'american airl',\n",
       "       u'reuters healt', u'abbvie is on ', u'speaking at @',\n",
       "       u'big pharma cr', u'to date, 80,0', u'$abbv listen ',\n",
       "       u'scientist , t', u'@ofh_john @ab', u'we see the go',\n",
       "       u'abbvie, celge', u'i love to see', u'@abbvie is th',\n",
       "       u'@abbvie color', u'@abbvie color', u'@abbvie color',\n",
       "       u'thank you to ', u'abbvie<u+2019', u'#job abbvie i',\n",
       "       u'very interest', u'great job in ', u'grateful to o',\n",
       "       u'help focus on', u'and also how ', u'@abbvie good.',\n",
       "       u'#ilc2017 indu', u'#ilc2017 indu', u'abbvie #cance',\n",
       "       u'reuters healt', u'great perspec', u'what drove am',\n",
       "       u'thank you @am', u'sure what els', u'huge thanks t',\n",
       "       u'we cant wait ', u'thanks to @am', u'celebrating #',\n",
       "       u'evening mover', u'#amgen inc. a', u'is #bigdata t',\n",
       "       u'@cgrantwsj th', u'#amgen tops 1', u'#trumpt  lies',\n",
       "       u'#amgen, sando', u'wall street f', u'#stemdiscover',\n",
       "       u'thanks @ncb_n', u'amgen, inc. $', u'this is great',\n",
       "       u'novartis: stu', u'is amgen losi', u'#biotech: 3 t',\n",
       "       u'#360wisenews ', u'thanks for th', u'a huge thank ',\n",
       "       u'the unholy jo', u'amgen to co-p', u'\"i want to ta',\n",
       "       u'amgen, inc. $', u'afternoon wit', u'congratulatio',\n",
       "       u'amgen, inc. $', u'#hallmarkies ', u'we know why t',\n",
       "       u'already at wa', u'@christinawil', u'high school s',\n",
       "       u'amgen files f', u'teachers reti', u'dears,anyone ',\n",
       "       u'we present a ', u'#3novices : a', u'adalimumab in',\n",
       "       u'prediction of', u'safety of lon', u\"doesn't #humi\"],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['message'].values.astype('U13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f3b9189d1d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munidecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'U13'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/imacair/anaconda/lib/python2.7/site-packages/unidecode/__init__.pyc\u001b[0m in \u001b[0;36munidecode_expect_ascii\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0m_warn_if_not_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mbytestring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ASCII'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unidecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "#unidecode(data['message'].values.astype('U13'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['message'].values)\n",
    "X = tokenizer.texts_to_sequences(data['message'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imacair/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "/Users/imacair/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(196, dropout=0.2, recurrent_dropout=0.2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 128)          256000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 985       \n",
      "=================================================================\n",
      "Total params: 511,785\n",
      "Trainable params: 511,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1], dropout=0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((646, 100), (646, 5))\n",
      "((319, 100), (319, 5))\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 24)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    4, 1494,  507],\n",
       "       [   0,    0,    0, ...,   16,    1,  286],\n",
       "       [   0,    0,    0, ...,    8,   44,   47],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,   55,  501,    5],\n",
       "       [   0,    0,    0, ...,    5,    6,   85],\n",
       "       [   0,    0,    0, ...,    4,    7, 1148]], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "14s - loss: 0.6568 - acc: 0.7895\n",
      "Epoch 2/7\n",
      "14s - loss: 0.3985 - acc: 0.8963\n",
      "Epoch 3/7\n",
      "14s - loss: 0.2569 - acc: 0.9288\n",
      "Epoch 4/7\n",
      "13s - loss: 0.1812 - acc: 0.9474\n",
      "Epoch 5/7\n",
      "15s - loss: 0.1418 - acc: 0.9659\n",
      "Epoch 6/7\n",
      "14s - loss: 0.1003 - acc: 0.9799\n",
      "Epoch 7/7\n",
      "13s - loss: 0.0759 - acc: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123b94450>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, nb_epoch = 7, batch_size=batch_size, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  125,  599,  453],\n",
       "       [   0,    0,    0, ...,    1,   16,   15],\n",
       "       [   0,    0,    0, ...,   39, 1981, 1982],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,  157,  420,  304],\n",
       "       [   0,    0,    0, ...,    9,  110,  198],\n",
       "       [   0,    0,    0, ...,  384,    5,  386]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 1.09\n",
      "acc: 0.72\n"
     ]
    }
   ],
   "source": [
    "validation_size = 100\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for x in range(len(X_validate)):\n",
    "    \n",
    "#    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.78      0.67         9\n",
      "          1       0.84      0.70      0.76        23\n",
      "          2       0.90      0.78      0.84        23\n",
      "          3       0.85      0.73      0.79        15\n",
      "          4       0.81      0.97      0.88        30\n",
      "\n",
      "avg / total       0.82      0.81      0.81       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validate,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros_like(out)\n",
    "b[np.arange(len(out)), out.argmax(1)] = 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(out[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out=model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
